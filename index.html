<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Context Canvas: Enhancing Text-to-Image Diffusion Models with Knowledge Graph-Based RAG</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Context Canvas: Enhancing Text-to-Image Diffusion Models with Knowledge Graph-Based RAG</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/kavanavenkatesh/">Kavana Venkatesh</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://yusufdalva.github.io/">Yusuf Dalva</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://isminoula.github.io/">Ismini Lourentzou</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://pinguar.org/">Pinar Yanardag</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Virginia Tech,</span>
            <span class="author-block"><sup>2</sup>University of Illinois Urbana-Champaign</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                  </a>
              </span>

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-widescreen">
    <div class="hero-body">
      <!-- TL;DR Section -->
      <h2 class="title is-5" style="font-weight: 400; text-align: justify; margin-bottom: 20px; color: #444;">
        <strong>TL;DR</strong> We propose a training-free approach that leverages knowledge graph-based Retrieval Augmented Generation to 
        enhance image generation and editing of text-to-image diffusion models. We also introduce a novel RAG context-guided self-correction mechanism. 
        The approach enables generation of contextually and narratively accurate images for
        complex, domain-specific scenarios that standard T2I models struggle with, using simple high-level user prompts.
      </h2>
      <!-- Teaser image -->
      <img id="teaser-image" src="./static/images/teaser.jpg" alt="Teaser Image" style="width: 120%; height: auto;">
      <h2 class="subtitle teaser-caption" style="font-size: 1rem; text-align: justify;">
      <span class="dnerf">Context Canvas</span> significantly improves image generation for domain-specific, complex characters that T2I models might
        otherwise struggle with (top left). Additionally, our method enables disentangled image editing by extracting precise item descriptions,
        such as transforming a simple “add a sword” prompt into a fire sword for the character Jambavan. It also adeptly captures relationships
        by utilizing the graph, for instance, generating Jambavan’s daughter from a simple “with his daughter” prompt, without needing explicit
        details about her appearance (bottom middle). Moreover, we introduce a novel RAG-based self-correction technique that further refines
        images to improve visual and narrative accuracy (right).
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We introduce a novel approach to enhance the capabilities of text-to-image models by incorporating Retrieval-Augmented Generation 
            with a knowledge graph. Our system dynamically retrieves detailed character information
            and relational data from the knowledge graph, enabling the
            generation of visually accurate and contextually rich images. Furthermore, we propose a self-correcting mechanism 
            within Stable Diffusion models to ensure consistency
            and fidelity in visual outputs, leveraging the rich context
            from the graph to guide corrections. To our knowledge, <span class="dnerf">Context Canvas</span> represents 
            the first application of graph-based RAG in enhancing
            T2I models, representing a significant advancement for producing high-fidelity, context-aware multi-faceted images.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper Methodology. -->
    <div class="columns is-centered">
  <div class="column">
    <!-- Paper Method Diagram -->
    <h2 class="title is-3 has-text-centered">Method</h2>
    <div class="publication-diagram" style="text-align: center;">
      <img id="method-diagram" src="./static/images/method-diagram.jpg" alt="Paper Method Diagram" style="width: 100%; height: auto; margin-top: 20px;">
      <h2 class="subtitle method-caption" style="font-size: 1rem; text-align: justify; margin-top: 10px; max-width: 1200px; margin-left: auto; margin-right: auto;">
        Context Canvas introduces a novel knowledge graph-based Retrieval-Augmented Generation (RAG) framework to 
        enhance text-to-image diffusion models for context-driven generation and editing of images with complex, 
        domain-specific concepts. The framework includes three key stages: 
        knowledge graph-driven image generation, context-aware image editing, and a novel self-correction mechanism. 
        In the first stage, user prompts are enriched with detailed character attributes and relationships from the knowledge graph, 
        enabling precise depictions. The editing stage seamlessly integrates specific items or features into images by retrieving relevant contextual data. 
        Finally, the self-correction process iteratively refines image outputs using RAG context-guided prompts to ensure alignment 
        with intended narratives and visual fidelity, addressing complex character traits and ensuring coherence across 
        cultural and contextual dimensions.
      </h2>
    </div>
  </div>
</div>
</section>

<section class="section">
  <div class="container is-max-widescreen">
    <!-- Qualitative Results Main Heading -->
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h2 class="title is-3">Qualitative Results</h2>
      </div>
    </div>

    <!-- Image Generation Subheading -->
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h3 class="title is-4">Image Generation</h3>
      </div>
    </div>

    <!-- Image Generation Results -->
    <div class="columns is-centered">
      <div class="column">
        <div class="content has-text-centered">
          <img id="image-generation" src="./static/images/image-generation.jpg" alt="Image Generation" style="width: 120%; height: auto;">
          <h2 class="subtitle image-generation" style="font-size: 1rem; text-align: justify;">
            Our method enhances image generation across diverse domains by integrating cultural and contextual details often missed by
            standard models. For example, it accurately portrays rare Indian mythological characters like Tumburu with his horse-face and instrument,
            and Gandabherunda as a dual-headed bird (top left). It also refines depictions of Makara’s hybrid form and Kumbhakarna’s horns (second
            row, left), which Flux omits. Our method adapts to various mythologies, capturing Melinoe’s ghostly essence (left bottom) and Zhong Kui’s
            fierce warrior form (middle bottom). In Project Gutenberg domains, such as Historical Fiction, Gothic Horror, and Fantasy, it captures
            narrative-specific details like Captain Ahab’s ivory leg and gaunt expression (top 4th column) and Edmond Dant`es’ pale skin, coat, and ring
            (top 3rd column). For Gothic Horror, it enhances Count Dracula’s menacing presence (middle 3rd column) and infers Manfred’s guilty,
            dark persona (middle 4th column). Unlike Flux’s generic depictions, our approach faithfully represents Lilith with bat wings and snakes
            and Lizarel with ethereal beauty and silvery hair (bottom right), demonstrating superior fidelity across cultural and literary domains.
          </h2>
        </div>
      </div>
    </div>

    <!-- Self-Correction Subheading -->
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h3 class="title is-4">Self-Correction</h3>
      </div>
    </div>
    
    <!-- Self-Correction Results -->
    <div class="columns is-centered">
      <div class="column">
        <div class="content has-text-centered">
          <img id="self-correction" src="./static/images/self-correction.jpg" alt="Self-Correction Results" style="width: 100%; height: auto; margin-top: 20px;">
          <h2 class="subtitle self-correction-caption" style="font-size: 1rem; text-align: justify; margin-top: 10px;">
            The self-correction mechanism refines generated images to better align with intended narratives and contextual fidelity.
            For instance, it improves the alignment of Tumburu’s horse-face proportions, enhances the accuracy of Gandabherunda’s dual-headed bird depiction,
            and adjusts Melinoe’s ghostly appearance to maintain consistency across cultural attributes. In literary contexts, our self-correction
            process fine-tunes narrative-specific details such as Captain Ahab’s ivory leg, Count Dracula’s menacing aura, and Lilith’s bat wings.
            These corrections ensure visual and semantic coherence, addressing omissions and ambiguities in the initial generation.
          </h2>
        </div>
      </div>
    </div>

    <!-- Placeholder for Editing and Self-Correction Results -->
    <div class="columns is-centered" id="additional-content" style="margin-top: 30px;">
      <div class="column">
        <!-- Example Placeholder for Editing -->
        <h3 class="title is-4 has-text-centered">Editing</h3>
        <img id="editing-results" src="./static/images/editing-results.jpg" alt="Editing Results" style="width: 100%; height: auto; margin-top: 20px;">
        <h2 class="subtitle result-caption" style="font-size: 1rem; text-align: justify; margin-top: 10px; max-width: 1200px; margin-left: auto; margin-right: auto;">
          This figure showcases the editing capabilities of our framework, enabling dynamic adjustments to generated images using retrieved context.
        </h2>
      </div>
    </div>
  </div>
</section>




    
       






<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{venkatesh2024contextcanvas,
  author    = {Venkatesh, Kavana and Dalva, Yusuf and Lourentzou, Ismini and Yanardag, Pinar },
  title     = {Context Canvas: Enhancing Text-to-Image Diffusion Models with Knowledge Graph-Based RAG},
  journal   = {arXiv preprint},
  year      = {2024},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is is adapted from <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website, 
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
