<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Context Canvas: Enhancing Text-to-Image Diffusion Models with Knowledge Graph-Based RAG</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Context Canvas: Enhancing Text-to-Image Diffusion Models with Knowledge Graph-Based RAG</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/kavanavenkatesh/">Kavana Venkatesh</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://yusufdalva.github.io/">Yusuf Dalva</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://isminoula.github.io/">Ismini Lourentzou</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://pinguar.org/">Pinar Yanardag</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Virginia Tech,</span>
            <span class="author-block"><sup>2</sup>University of Illinois Urbana-Champaign</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                  </a>
              </span>

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- TL;DR Section -->
      <h2 class="title is-5" style="font-weight: 400; text-align: justify; margin-bottom: 20px; color: #444;">
        <strong>TL;DR</strong> We propose a training-free approach that leverages knowledge graph-based Retrieval Augmented Generation to 
        enhance image generation and editing of text-to-image diffusion models. We also introduce a novel RAG context-guided self-correction mechanism. 
        The approach enables generation of contextually and narratively accurate images for
        complex, domain-specific scenarios that standard T2I models struggle with, using simple high-level user prompts.
      </h2>
      <!-- Teaser image -->
      <img id="teaser-image" src="./static/images/teaser.jpg" alt="Teaser Image" style="width: 120%; height: auto;">
      <h2 class="subtitle teaser-caption" style="font-size: 1rem; text-align: justify;">
      <span class="dnerf">Context Canvas</span> significantly improves image generation for domain-specific, complex characters that T2I models might
        otherwise struggle with (top left). Additionally, our method enables disentangled image editing by extracting precise item descriptions,
        such as transforming a simple “add a sword” prompt into a fire sword for the character Jambavan. It also adeptly captures relationships
        by utilizing the graph, for instance, generating Jambavan’s daughter from a simple “with his daughter” prompt, without needing explicit
        details about her appearance (bottom middle). Moreover, we introduce a novel RAG-based self-correction technique that further refines
        images to improve visual and narrative accuracy (right).
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We introduce a novel approach to enhance the capabilities of text-to-image models by incorporating Retrieval-Augmented Generation 
            with a knowledge graph. Our system dynamically retrieves detailed character information
            and relational data from the knowledge graph, enabling the
            generation of visually accurate and contextually rich images. Furthermore, we propose a self-correcting mechanism 
            within Stable Diffusion models to ensure consistency
            and fidelity in visual outputs, leveraging the rich context
            from the graph to guide corrections. To our knowledge, <span class="dnerf">Context Canvas</span> represents 
            the first application of graph-based RAG in enhancing
            T2I models, representing a significant advancement for producing high-fidelity, context-aware multi-faceted images.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper Methodology. -->
    <div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <!-- Paper Method Diagram -->
    <h2 class="title is-3">Method</h2>
    <div class="publication-diagram">
      <img id="method-diagram" src="./static/images/method-diagram.jpg" alt="Paper Method Diagram" style="width: 150%; height: auto;">
      <h2 class="subtitle method-caption" style="font-size: 1rem; text-align: justify; margin-top: 10px;">
        Context Canvas introduces a novel a knowledge graph-based Retrieval-Augmented Generation (RAG) framework to 
        enhance text-to-image diffusion models for context-driven generation and editing of images with complex, 
        domain-specific concepts. The framework includes three key stages: 
        knowledge graph-driven image generation, context-aware image editing, and a novel self-correction mechanism. 
        In the first stage, user prompts are enriched with detailed character attributes and relationships from the knowledge graph, 
        enabling precise depictions. The editing stage seamlessly integrates specific items or features into images by retrieving relevant contextual data. 
        Finally, the self-correction process iteratively refines image outputs using RAG context-guided prompts to ensure alignment 
        with intended narratives and visual fidelity, addressing complex character traits and ensuring coherence across 
        cultural and contextual dimensions.
      </h2>
    </div>
  </div>
</div>

</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Qualitative Results Main Heading -->
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h2 class="title is-3">Qualitative Results</h2>
      </div>
    </div>

    <!-- Image Generation Subheading -->
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h3 class="title is-4">Image Generation</h3>
      </div>
    </div>

    <!-- Image Generation Results -->
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-centered">
          <img id="image-generation" src="./static/images/image-generation.jpg" alt="Image Generation Results" style="width: 100%; height: auto; margin-top: 20px;">
          <h2 class="subtitle result-caption" style="font-size: 1rem; text-align: justify; margin-top: 10px;">
            This figure demonstrates the image generation capabilities of our proposed method. The framework retrieves relevant knowledge from the graph to generate semantically meaningful and contextually accurate images, tailored to specific prompts.
          </h2>
        </div>
      </div>
    </div>

    <!-- Placeholder for Editing and Self-Correction Results -->
    <div class="columns is-centered" id="additional-content" style="margin-top: 30px;">
      <!-- Add editing and self-correction content here -->
    </div>
  </div>
</section>




    
       






<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{venkatesh2024contextcanvas,
  author    = {Venkatesh, Kavana and Dalva, Yusuf and Lourentzou, Ismini and Yanardag, Pinar },
  title     = {Context Canvas: Enhancing Text-to-Image Diffusion Models with Knowledge Graph-Based RAG},
  journal   = {arXiv preprint},
  year      = {2024},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is is adapted from <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website, 
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
